name: ğŸ“Š Automated Grading - Reddit Browser (Task 03)

# Trigger on every push to main/master
on:
  push:
    branches:
      - main
      - master
    paths:
      - 'Task 03/submissions/**'  # Only trigger if submissions folder changes
  pull_request:
    branches:
      - main
      - master
    paths:
      - 'Task 03/submissions/**'
  # Allow manual trigger from Actions tab
  workflow_dispatch:

permissions:
    contents: write

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      changed-students: ${{ steps.detect.outputs.students }}
      has-changes: ${{ steps.detect.outputs.has-changes }}
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ” Detect changed submissions
        id: detect
        run: |
          SUBMISSIONS_DIR="Task 03/submissions"
          
          if [ ! -d "$SUBMISSIONS_DIR" ]; then
            echo "has-changes=false" >> $GITHUB_OUTPUT
            echo "students=" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Get list of changed files
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            # Manual trigger - grade ALL submissions
            echo "ğŸ“Œ Manual trigger detected - grading ALL submissions"
            CHANGED_FILES=$(find "$SUBMISSIONS_DIR" -name "index.html" -type f)
          elif [ "${{ github.event_name }}" == "pull_request" ]; then
            # For PR, compare with base branch
            CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD)
          else
            # For push, compare with previous commit
            if [ "${{ github.event.before }}" == "0000000000000000000000000000000000000000" ]; then
              # Initial commit - grade all
              CHANGED_FILES=$(find "$SUBMISSIONS_DIR" -name "index.html" -type f)
            else
              CHANGED_FILES=$(git diff --name-only ${{ github.event.before }} HEAD)
            fi
          fi
          
          # Extract student folders that changed
          STUDENTS=$(echo "$CHANGED_FILES" | grep "Task 03/submissions/" | cut -d'/' -f3 | sort -u)
          
          if [ -z "$STUDENTS" ]; then
            echo "â„¹ï¸  No submissions changed"
            echo "has-changes=false" >> $GITHUB_OUTPUT
            echo "students=" >> $GITHUB_OUTPUT
          else
            echo "âœ… Changed students:"
            echo "$STUDENTS" | while read -r student; do
              echo "  - $student"
            done
            echo "has-changes=true" >> $GITHUB_OUTPUT
            echo "students<<EOF" >> $GITHUB_OUTPUT
            echo "$STUDENTS" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi

  grade-submissions:
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.PAT_TOKEN }}
          persist-credentials: true

      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ğŸ” Grade changed submissions only
        run: |
          python3 << 'EOF'
          import os
          import json
          import re
          
          SUBMISSIONS_DIR = "Task 03/submissions"
          CHANGED_STUDENTS = """${{ needs.detect-changes.outputs.changed-students }}""".strip().split('\n')
          
          print("ğŸ¯ Grading changed submissions only:")
          print(f"Students to grade: {len(CHANGED_STUDENTS)}")
          for student in CHANGED_STUDENTS:
              print(f"  âœ“ {student}")
          print()
          
          def grade_submission(student_folder, index_file):
              """Grade a single submission based on Reddit Browser requirements"""
              with open(index_file, 'r', encoding='utf-8') as f:
                  content = f.read()
              
              content_lower = content.lower()
              
              scores = {
                  'file_structure': 5,
                  'functionality': 0,
                  'ui_design': 0,
                  'code_quality': 0,
                  'responsive': 0,
                  'issues': []
              }
              
              # ===== FUNCTIONALITY (40 points) =====
              
              # Step 1: Fetch Reddit API (8 pts)
              if 'fetch(' in content_lower and 'reddit.com' in content_lower:
                  scores['functionality'] += 8
              else:
                  scores['issues'].append('âŒ No Reddit API fetch')
              
              # Step 2: Display posts function (8 pts)
              if re.search(r'function\s+displayposts|displayposts\s*=|const\s+displayposts', content_lower):
                  scores['functionality'] += 8
              else:
                  scores['issues'].append('âŒ No displayPosts function')
              
              # Step 4: Search/loadPosts function (8 pts)
              if re.search(r'function\s+loadposts|loadposts\s*=|getelementbyid.*input', content_lower):
                  scores['functionality'] += 8
              else:
                  scores['issues'].append('âš ï¸ No loadPosts/search function')
              
              # Async/await or .then() (6 pts)
              if 'async' in content_lower or '.then(' in content_lower:
                  scores['functionality'] += 6
              else:
                  scores['issues'].append('âš ï¸ No async handling')
              
              # Error handling (10 pts)
              if 'catch' in content_lower or 'try' in content_lower:
                  scores['functionality'] += 10
              else:
                  scores['issues'].append('âŒ No error handling')
              
              # ===== UI/DESIGN (30 points) =====
              
              # Step 3: Grid layout (10 pts)
              if 'display: grid' in content_lower or 'display:grid' in content_lower:
                  scores['ui_design'] += 10
              elif 'grid' in content_lower:
                  scores['ui_design'] += 5
              else:
                  scores['issues'].append('âŒ No CSS grid layout')
              
              # Post cards with images (8 pts)
              if 'post-card' in content_lower or 'postcard' in content_lower:
                  scores['ui_design'] += 4
              if '<img' in content_lower and 'thumbnail' in content_lower:
                  scores['ui_design'] += 4
              else:
                  scores['issues'].append('âš ï¸ No image/thumbnail handling')
              
              # Stats display: upvotes, comments, author (7 pts)
              stats_count = 0
              if 'ups' in content_lower or 'upvote' in content_lower:
                  stats_count += 1
              if 'num_comments' in content_lower or 'comment' in content_lower:
                  stats_count += 1
              if 'author' in content_lower:
                  stats_count += 1
              scores['ui_design'] += min(stats_count * 2, 7)
              
              # Step 5: Custom styling (5 pts)
              if '<style>' in content_lower and len(re.findall(r'[{]', content)) > 10:
                  scores['ui_design'] += 5
              elif '<style>' in content_lower:
                  scores['ui_design'] += 2
              else:
                  scores['issues'].append('âš ï¸ Minimal CSS styling')
              
              # ===== CODE QUALITY (15 points) =====
              
              # Multiple functions (5 pts)
              function_count = len(re.findall(r'function\s+\w+|const\s+\w+\s*=\s*(?:async\s*)?\(', content))
              if function_count >= 3:
                  scores['code_quality'] += 5
              elif function_count >= 2:
                  scores['code_quality'] += 3
              
              # DOM manipulation (5 pts)
              if 'getelementbyid' in content_lower or 'queryselector' in content_lower:
                  scores['code_quality'] += 5
              
              # Clean code - no excessive console.log (5 pts)
              console_count = content_lower.count('console.log')
              if console_count <= 2:
                  scores['code_quality'] += 5
              elif console_count <= 5:
                  scores['code_quality'] += 3
              
              # ===== RESPONSIVE DESIGN (10 points) =====
              
              # Media queries (8 pts)
              if '@media' in content_lower:
                  scores['responsive'] += 8
              else:
                  scores['issues'].append('âš ï¸ No @media queries for mobile')
              
              # Flexbox or grid for responsive (2 pts)
              if 'flex' in content_lower or 'auto-fill' in content_lower or 'auto-fit' in content_lower:
                  scores['responsive'] += 2
              
              # ===== BONUS: Video support (up to 5 extra) =====
              if 'reddit_video' in content_lower or '<video' in content_lower:
                  scores['functionality'] = min(scores['functionality'] + 5, 45)
              
              return scores
          
          # Process ONLY changed submissions
          results = []
          
          for student in CHANGED_STUDENTS:
              if not student.strip():
                  continue
              
              student_path = os.path.join(SUBMISSIONS_DIR, student.strip())
              index_file = os.path.join(student_path, "index.html")
              
              if not os.path.exists(index_file):
                  print(f"âš ï¸  {student}: Missing index.html")
                  continue
              
              scores = grade_submission(student, index_file)
              total = sum([
                  scores['file_structure'],
                  scores['functionality'],
                  scores['ui_design'],
                  scores['code_quality'],
                  scores['responsive']
              ])
              
              # Cap at 100
              total = min(total, 100)
              
              # Determine grade
              if total >= 90:
                  grade = 'A'
              elif total >= 80:
                  grade = 'B'
              elif total >= 70:
                  grade = 'C'
              elif total >= 60:
                  grade = 'D'
              else:
                  grade = 'F'
              
              result = {
                  'student': student.strip(),
                  **scores,
                  'total': total,
                  'grade': grade
              }
              results.append(result)
              
              print(f"âœ… {student}")
              print(f"   Score: {total}/100 - Grade: {grade}")
              if result['issues']:
                  for issue in result['issues'][:3]:
                      print(f"   {issue}")
          
          # Save results
          with open('grading_results.json', 'w') as f:
              json.dump(results, f, indent=2)
          
          # Print summary
          print("\n" + "="*50)
          print("ğŸ“Š SUMMARY")
          print("="*50)
          print(f"Submissions graded: {len(results)}")
          if results:
              avg_score = sum(r['total'] for r in results) / len(results)
              print(f"Average score: {avg_score:.1f}/100")
              
              for grade in ['A', 'B', 'C', 'D', 'F']:
                  count = sum(1 for r in results if r['grade'] == grade)
                  if count > 0:
                      print(f"  {grade}: {count}")
          
          EOF

      - name: ğŸ“„ Generate markdown report
        if: always()
        run: |
          python3 << 'EOF'
          import json
          from datetime import datetime
          
          with open('grading_results.json', 'r') as f:
              results = json.load(f)
          
          current_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
          avg_score = round(sum(r['total'] for r in results) / len(results), 1) if results else 0
          
          report = f"""# ğŸ“Š Reddit Browser - Grading Report (Changed Submissions)

          Generated by GitHub Actions on: {current_date}

          ## Summary

          - **Submissions Graded:** {len(results)}
          - **Average Score:** {avg_score}/100

          ## Individual Results

          """
          
          for result in sorted(results, key=lambda x: x['total'], reverse=True):
              grade_emoji = {'A': 'ğŸ‰', 'B': 'ğŸ‘', 'C': 'ğŸ‘Œ', 'D': 'âš ï¸', 'F': 'âŒ'}
              emoji = grade_emoji.get(result['grade'], 'â“')
              
              report += f"""
          ### {result['student']} - {emoji} {result['grade']} ({result['total']}/100)

          | Category | Score |
          |----------|-------|
          | File Structure | {result['file_structure']}/5 |
          | Functionality | {result['functionality']}/40 |
          | UI/Design | {result['ui_design']}/30 |
          | Code Quality | {result['code_quality']}/15 |
          | Responsive | {result['responsive']}/10 |
          | **TOTAL** | **{result['total']}/100** |

          """
              
              if result['issues']:
                  report += "**Issues:**\n"
                  for issue in result['issues']:
                      report += f"- {issue}\n"
                  report += "\n"
          
          with open('GRADING_REPORT.md', 'w') as f:
              f.write(report)
          
          print("âœ… Report generated: GRADING_REPORT.md")
          EOF

      - name: ğŸ† Update README with Leaderboard
        if: always()
        run: |
          python3 << 'EOF'
          import json
          from datetime import datetime
          import os
          
          # Load current results
          with open('grading_results.json', 'r') as f:
              new_results = json.load(f)
          
          # Load existing leaderboard data if exists
          leaderboard_file = "Task 03/leaderboard_data.json"
          all_results = {}
          if os.path.exists(leaderboard_file):
              try:
                  with open(leaderboard_file, 'r') as f:
                      content = f.read().strip()
                      if content:
                          all_results = json.loads(content)
              except json.JSONDecodeError:
                  print("âš ï¸ Invalid JSON in leaderboard file, starting fresh")
                  all_results = {}
          
          # Update with new results
          current_time = datetime.now().strftime("%Y-%m-%d %H:%M UTC")
          for result in new_results:
              student = result['student']
              all_results[student] = {
                  **result,
                  'last_updated': current_time,
                  'submission_count': all_results.get(student, {}).get('submission_count', 0) + 1
              }
          
          # Save updated leaderboard data
          with open(leaderboard_file, 'w') as f:
              json.dump(all_results, f, indent=2)
          
          # Sort by: Score â†’ Last Updated Time (earliest wins)
          sorted_results = sorted(all_results.values(), key=lambda x: (
              -x['total'],                    # Primary: Total score (descending)
              x.get('last_updated', '9999'),  # Tiebreaker: Earlier submission wins (ascending)
              x['student']                    # Last resort: Alphabetical
          ))
          
          # Fun titles based on rank
          def get_title(rank, grade):
              if rank == 1:
                  return "ğŸ‘‘ Supreme Redditor"
              elif rank == 2:
                  return "ğŸ¥ˆ Code Wizard"
              elif rank == 3:
                  return "ğŸ¥‰ Rising Star"
              elif grade == 'A':
                  return "ğŸŒŸ Reddit Master"
              elif grade == 'B':
                  return "ğŸ’ª Skilled Coder"
              elif grade == 'C':
                  return "ğŸ“ˆ Making Progress"
              elif grade == 'D':
                  return "ğŸ”§ Keep Pushing"
              else:
                  return "ğŸš€ Just Getting Started"
          
          # Generate README
          readme = """# ğŸ† Reddit Browser Challenge - Live Leaderboard

          > *"In the arena of code, only the brave submit their work!"* ğŸ®

          ![Last Updated](https://img.shields.io/badge/Last%20Updated-""" + current_time.replace(" ", "%20").replace(":", "%3A") + """-blue)
          ![Submissions](https://img.shields.io/badge/Submissions-""" + str(len(sorted_results)) + """-green)

          ## ğŸ¯ The Challenge
          Build a Reddit Browser that fetches real data, displays posts beautifully, and works on mobile!

          ---

          ## ğŸ… Hall of Fame

          """
          
          # Top 3 podium
          if len(sorted_results) >= 1:
              readme += "### ğŸ¥‡ First Place\n"
              r = sorted_results[0]
              readme += f"**{r['student']}** - {r['total']}/100\n\n"
          
          if len(sorted_results) >= 2:
              readme += "### ğŸ¥ˆ Second Place\n"
              r = sorted_results[1]
              readme += f"**{r['student']}** - {r['total']}/100\n\n"
          
          if len(sorted_results) >= 3:
              readme += "### ğŸ¥‰ Third Place\n"
              r = sorted_results[2]
              readme += f"**{r['student']}** - {r['total']}/100\n\n"
          
          readme += """---

          ## ğŸ“Š Full Leaderboard

          | Rank | Student | Score | Grade | Title | Last Updated |
          |:----:|---------|:-----:|:-----:|-------|--------------|
          """
          
          for i, result in enumerate(sorted_results, 1):
              grade_emoji = {'A': 'ğŸ”¥', 'B': 'âœ¨', 'C': 'ğŸ‘Œ', 'D': 'ğŸ“', 'F': 'ğŸ”¨'}
              emoji = grade_emoji.get(result['grade'], 'â“')
              title = get_title(i, result['grade'])
              
              # Medal for top 3
              rank_display = {1: 'ğŸ¥‡', 2: 'ğŸ¥ˆ', 3: 'ğŸ¥‰'}.get(i, str(i))
              
              readme += f"| {rank_display} | **{result['student']}** | {result['total']}/100 | {emoji} {result['grade']} | {title} | {result.get('last_updated', 'N/A')} |\n"
          
          readme += """
          ---

          ## ğŸ“ˆ Score Breakdown

          | Category | Points | What We're Looking For |
          |----------|:------:|------------------------|
          | ğŸ“ File Structure | 5 | Proper index.html setup |
          | âš¡ Functionality | 40 | API fetch, display posts, search, async/await, error handling |
          | ğŸ¨ UI/Design | 30 | CSS Grid, post cards, thumbnails, stats display |
          | ğŸ’» Code Quality | 15 | Multiple functions, DOM manipulation, clean code |
          | ğŸ“± Responsive | 10 | Media queries, mobile-friendly |
          | ğŸ Bonus | +5 | Video support |

          ---

          ## ğŸš€ Recent Activity

          """
          
          # Show last 5 updates
          recent = sorted(sorted_results, key=lambda x: x.get('last_updated', ''), reverse=True)[:5]
          for r in recent:
              readme += f"- **{r['student']}** updated their submission â†’ {r['total']}/100 ({r.get('last_updated', 'N/A')})\n"
          
          readme += """
          ---

          ## ğŸ’¡ Tips to Improve Your Score

          1. **Use `fetch()` with Reddit API** - Don't forget async/await!
          2. **Create a `displayPosts` function** - Keep your code organized
          3. **Add CSS Grid** - `display: grid` is your friend
          4. **Handle errors** - Wrap fetches in try/catch
          5. **Add @media queries** - Make it mobile-friendly
          6. **Show thumbnails** - Reddit provides image URLs

          ---

          <p align="center">
            <i>ğŸ¤– Auto-graded by GitHub Actions | May the code be with you! ğŸŒŸ</i>
          </p>
          """
          
          with open('Task 03/README.md', 'w') as f:
              f.write(readme)
          
          print("âœ… README.md updated with leaderboard!")
          EOF

      - name: ğŸ“¤ Commit and Push README
        if: github.event_name != 'pull_request' && always()
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git remote set-url origin https://x-access-token:${{ secrets.PAT_TOKEN }}@github.com/${{ github.repository }}.git
          git add "Task 03/README.md" "Task 03/leaderboard_data.json"
          git diff --staged --quiet || git commit -m "ğŸ† Update leaderboard - $(date +'%Y-%m-%d %H:%M')"
          git push
        env:
          PAT_TOKEN: ${{ secrets.PAT_TOKEN }}

      - name: ğŸ“¦ Upload grading results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: grading-results-changed
          path: |
            grading_results.json
            GRADING_REPORT.md

      - name: ğŸ’¬ Comment on PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('grading_results.json', 'utf8'));
            
            let comment = '# ğŸ“Š Grading Results (Changed Submissions Only)\n\n';
            comment += `- **Submissions Graded:** ${results.length}\n`;
            
            if (results.length > 0) {
              const avg = (results.reduce((sum, r) => sum + r.total, 0) / results.length).toFixed(1);
              comment += `- **Average Score:** ${avg}/100\n\n`;
              
              comment += '### Results:\n\n';
              results.forEach(r => {
                const emoji = {'A': 'ğŸ‰', 'B': 'ğŸ‘', 'C': 'ğŸ‘Œ', 'D': 'âš ï¸', 'F': 'âŒ'}[r.grade] || 'â“';
                comment += `- **${r.student}**: ${emoji} ${r.grade} (${r.total}/100)\n`;
              });
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: ğŸ“ˆ Create job summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # ğŸ“Š Grading Complete (Changed Submissions)
          
          âœ… Only changed submissions were graded
          ğŸ“„ Report generated
          ğŸ“¦ Results available as artifact
          EOF

  no-changes:
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'false'
    runs-on: ubuntu-latest
    steps:
      - name: â„¹ï¸ No changes detected
        run: |
          echo "â„¹ï¸  No submissions were changed in this push"
          echo "Skipping grading workflow"
